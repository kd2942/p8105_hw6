---
title: "p8105 Hw#6"
author: "Kaylin De Silva"
date: 12-02-2024
output: github_document
---
```{r load libraries}
#loading libraries and setting seed for reproducibility  
library(tidyverse)
library(dplyr)
library(rvest)
library(modelr)
library(mgcv)
library("SemiPar")
set.seed(1)
```
This chunk loads the tidyverse, rvest, and dplyr libraries and fixes the output. 

**Problem 2**
```{r loading dataset problem 2}
#loading csv
raw_washington_df = read.csv(file = "./homicide-data.csv")

#viewing variables
head(raw_washington_df)
```
The data set has 52,179 observations and 12 columns. 

```{r manipulating data by creating variables and filtering observations as needed}
#creating a city_state variable and removing cities and races that are not needed for analysis
washington_df = raw_washington_df |>
  mutate(
    city_state = paste(city, state, sep=", "),
    solved = ifelse(disposition == "Closed by arrest", 1, 0)) |>
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
    ),
    victim_race %in% c("Black", "White")) |>
  mutate(
    victim_age = as.numeric(victim_age)) |>
  drop_na() |>
  mutate(
  victim_sex = fct_relevel(victim_sex, "Male"))
```
This chunk removes observations not needed for the analyses. It also mutates age as a numeric variable so the regression models can effectively use it as a continuous variable. Victim sex is releveled so that Male is the reference group. 

```{r glm for Baltimore}
#logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors
fit_logistic = 
  washington_df |>
  filter(city_state == "Baltimore, MD")|> 
  glm(solved ~ victim_sex + victim_race + victim_age, data = _, family = binomial()) 

#saving glm output and tidying it
fit_logistic |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    CI_upper = exp((estimate) + 1.96*(std.error)),
    CI_lower = exp((estimate) - 1.96*(std.error))) |>
  select(term, log_OR = estimate, OR, p.value, CI_upper, CI_lower) |> 
  knitr::kable(digits = 3)
```
In Baltimore, the odds of a homicide being solved when the victim was a male was 2.350 (95% CI: 1.793, 3.081) times the odds of a homicide being solved when the victim was a female, controlling for the victim's age and race. The beta estimate for this adjusted odds ratio is 0.854. 

```{r glm for all cities}
# glm for each of the cities in the dataset
nest_glm_city_state =
  washington_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(solved ~ victim_sex + victim_race + victim_age, data = df)),
    results = map(models, broom::tidy)) |> 
  select(-data, -models) |> 
  unnest(results)

#extracting the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims
nest_glm_city_state |> 
  select(term, estimate, city_state, std.error, p.value) |>
  mutate(
    term = fct_inorder(term),
    OR = exp(estimate),
    CI_upper = exp((estimate) + 1.96*(std.error)),
    CI_lower = exp((estimate) - 1.96*(std.error))) |> 
  select(estimate, term, city_state, OR, CI_upper, CI_lower)|>
  filter(
    term == "victim_sexFemale"
  )|>
  pivot_wider(
    names_from = term, values_from = estimate)|>
  knitr::kable(digits = 3)
```
This code chunk uses the map function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors for each of the cities. The output was saved and filtered to obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims (keeping all other variables fixed).

```{r plotting glm output for all cities}
#filtering glm output and reordering it to plot ORs for each city
nest_glm_city_state |> 
  filter(
    term == "victim_sexFemale") |>
  mutate(city_state = fct_reorder(city_state, exp(estimate))) |>
  ggplot(aes(x = city_state, y = exp(estimate))) + 
  geom_point() + 
  geom_errorbar(aes(x=city_state, 
        ymin = exp((estimate) + 1.96*(std.error)), 
        ymax = exp((estimate) - 1.96*(std.error)))) +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "OR for Solving Homicides Comparing Male Victims to Female Victims by City",
    x = "City",
    y = "Estimated OR (with 95% CI)"
  )
```
The plot highlights the variety of confidence interval widths, with wider intervals occurring at the lower and higher OR values. It also makes it evident that around half of the ORs have confidence intervals that include the null value of 1, indicating that though almost all estimates are greater than 1, they are not all statistically significant. 

**Problem 3**
```{r loading dataset}
#loading csv
raw_birthweight_df = read.csv(file = "./birthweight.csv")

#viewing variables
head(raw_birthweight_df)
```
The data set has 4,342 observations and 20 variables. 

```{r tidying data set for analysis}
#mutating mother's race, baby sex, father's race, baby length, and mother's pre-pregnany weight for analysis
birthweight_df = raw_birthweight_df |>
  mutate(
    mrace = 
      case_match(mrace,
        1 ~ "White", 
        2 ~ "Black", 
        3 ~ "Asian",
        4 ~ "Puerto Rican",
        8 ~ "Other"),
    babysex = 
      case_match(babysex,
        1 ~ "Male",
        2 ~ "Female"),
    frace = 
      case_match(frace,
        1 ~ "White", 
        2 ~ "Black", 
        3 ~ "Asian",
        4 ~ "Puerto Rican",
        8 ~ "Other",
        9 ~ "Unknown")
  ) |>
  drop_na() |>
  mutate(
    babysex = as.factor(babysex),
    blength = as.numeric(blength),
    ppwt = as.numeric(ppwt))

str(birthweight_df)
```

```{r}
birthweight_df = as.data.frame(birthweight_df)
birthweight_fit = 
  birthweight_df |>
  lm(bwt ~ babysex + gaweeks + ppwt + blength + blength*gaweeks, data =_)

birthweight_fit |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    CI_upper = exp((estimate) + 1.96*(std.error)),
    CI_lower = exp((estimate) - 1.96*(std.error))) |>
  select(term, log_OR = estimate, OR, p.value, CI_upper, CI_lower) |> 
  knitr::kable(digits = 3)
```

```{r}
birthweight_df <- birthweight_df |> 
  add_predictions(birthweight_fit) |>  
  add_residuals(birthweight_fit)|>
  mutate(type = 
           if_else(!is.na(resid), "Residual", "Prediction"))

birthweight_df |>
  ggplot(aes(y=resid, x=pred)) +
    geom_point() +
  labs(
    title = "Predictions vs Residuals for Proposed Model",
    x = "Predictions",
    y = "Residuals")
```

```{r}
length_age_fit = 
  birthweight_df |>
  lm(bwt ~ gaweeks + blength, data =_)

length_age_fit |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    CI_upper = exp((estimate) + 1.96*(std.error)),
    CI_lower = exp((estimate) - 1.96*(std.error))) |>
  select(term, log_OR = estimate, OR, p.value, CI_upper, CI_lower) |> 
  knitr::kable(digits = 3)
```

```{r}
interaction_fit = 
  birthweight_df |>
  lm(bwt ~ bhead + blength + babysex + babysex*blength + babysex*bhead + blength*bhead + blength*bhead*babysex, data =_)

interaction_fit |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    CI_upper = exp((estimate) + 1.96*(std.error)),
    CI_lower = exp((estimate) - 1.96*(std.error))) |>
  select(term, log_OR = estimate, OR, p.value, CI_upper, CI_lower) |> 
  knitr::kable(digits = 3)
```

```{r}
cv_df =
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df |> 
  mutate(
    birthweight_fit= map(train, \(df) lm(bwt ~ babysex + gaweeks + ppwt + blength + blength*gaweeks, data = df)),
    length_age_fit= map(train, \(df) lm(bwt ~ gaweeks + blength, data = df)),
    interaction_fit  = map(train, \(df) gam(bwt ~ bhead + blength + babysex + babysex*blength + babysex*bhead + blength*bhead + blength*bhead*babysex, data = as_tibble(df)))) |> 
  mutate(
    rmse_birthweight = map2_dbl(birthweight_fit, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_lenght_age = map2_dbl(length_age_fit, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_fit, test, \(mod, df) rmse(model = mod, data = df)))
```

```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Model with interaction terms (including three level interaction) has a little more predictive accuracy. 
